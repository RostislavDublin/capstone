# Repository Quality Guardian

**Independent Quality Auditor for Engineering Teams**

[![Competition](https://img.shields.io/badge/Kaggle-5%20Day%20Agents%20Capstone-20BEFF)](https://kaggle.com/competitions/agents-intensive-capstone-project)
[![Track](https://img.shields.io/badge/Track-Enterprise%20Agents-green)]()
[![Framework](https://img.shields.io/badge/Framework-Google%20ADK-4285F4)]()
[![Status](https://img.shields.io/badge/Status-In%20Development-yellow)]()
[![Progress](https://img.shields.io/badge/Progress-Day%203-orange)]()
[![Days](https://img.shields.io/badge/Days%20Remaining-8-red)]()

> **Current Status (Day 3/10):** Backend tools verified (~15%) | Orchestration layer next

---

## The Problem

Engineering teams face constant pressure to ship fast. Quality often takes a back seat:
- Tech debt accumulates invisibly
- Same issues appear commit after commit
- No objective measure of quality trends
- Hard to justify "quality sprints" to management

**Traditional code review tools** focus on blocking PRs. But who watches the watchers? Who ensures quality standards don't slowly erode?

---

## Our Solution: The Independent Quality Guardian

An **AI-powered quality auditor** that:

‚úÖ **Monitors release branches** - Audits every commit to main/production  
‚úÖ **Never forgets** - Full history stored in RAG (Vertex AI)  
‚úÖ **Never compromises** - Strict quality standards, unaffected by team politics  
‚úÖ **Shows trends** - "Quality down 15% last month"  
‚úÖ **Provides insights** - Data-driven recommendations for sprint planning

### Target Audience

Not for developers during PR review. For **engineering leads** who need to:
- Track quality trends over time
- Identify persistent issues
- Make data-driven sprint decisions
- Justify quality initiatives to management

### Example Queries

```
"How has our code quality changed since Q3?"
"What security issues keep appearing?"
"Which parts of the codebase need refactoring?"
"Are we improving or degrading?"
"What should we focus on next sprint?"
```

---

## üèóÔ∏è Architecture: Conversational Agent

**Design:** No webhooks. User-initiated audits via natural language commands.

### Three Commands

```
User: "Bootstrap myorg/myrepo, last 6 months, tagged releases"
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Quality Guardian    ‚îÇ
    ‚îÇ (Conversational AI) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Repository Connector‚îÇ
    ‚îÇ (GitHub/GitLab API) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì                ‚Üì             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Security ‚îÇ  ‚îÇ Complexity  ‚îÇ  ‚îÇ   RAG    ‚îÇ
‚îÇ (Bandit) ‚îÇ  ‚îÇ  (Radon)    ‚îÇ  ‚îÇ Storage  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Command 1: bootstrap** - Initial historical scan  
**Command 2: sync** - Check for new commits  
**Command 3: query** - Ask about quality trends

### Example Conversation

```
üë§ User: "Connect to facebook/react and bootstrap using tags from 2024"

ü§ñ Agent: [Scanning repository...]
         ‚úì Found 24 tagged releases (v18.0.0 to v18.3.1)
         ‚úì Auditing commits... [24/24]
         ‚úì Complete. Stored 24 audits in RAG.
         
         Summary:
         - Security issues: 12 total (3 critical, 9 major)
         - Avg complexity: A- (excellent)
         - Quality trend: Stable
         
         Ready for queries.

üë§ User: "Show me security trends"

ü§ñ Agent: Security Analysis for facebook/react (2024)
         
         üìä Overall: Improving (12 ‚Üí 5 issues)
         
         üî¥ Critical Issues Found:
         - Prototype pollution (fixed in v18.2.0)
         - XSS vulnerability (fixed in v18.1.5)
         
         ‚úÖ Resolution Rate: 58% (7 of 12 fixed)
         
         üí° Recommendation: Remaining issues in hooks system

üë§ User: "Check for new commits"

ü§ñ Agent: ‚úì Synced facebook/react
         - 2 new commits since last audit (Nov 19)
         - No new issues detected
         - Quality maintained at A-
```

---

## üéØ Key Features

### 1. Historical Backfill (Cold Start Solution)
- **Instant value** for mature repositories
- **Scan past releases** - tags, weekly, or monthly snapshots
- **Sampling strategies** - balance cost vs completeness
- **Example:** Backfill 6 months of releases in one command

### 2. Full Repository Auditing
- **Not just diffs** - analyzes complete repository state
- **Security:** Bandit finds vulnerabilities (SQL injection, hardcoded secrets, etc.)
- **Complexity:** Radon measures cyclomatic complexity, maintainability
- **Quality Score:** Objective assessment on every commit

### 3. RAG-Powered Memory
- **Every audit stored** in Vertex AI RAG Corpus
- **Indexed by time** - query by date range
- **Semantic search** - natural language queries work
- **Never forgets** - complete history available

### 4. Trend Analysis
- **Quality trajectory** - improving or degrading?
- **Recurring issues** - same problems appearing repeatedly?
- **Hotspots** - which files/modules need attention?
- **Sprint recommendations** - data-driven focus areas

### 5. Independent Arbitrator
- **Unaffected by team politics** - no compromises
- **Consistent standards** - doesn't drift over time
- **Objective evidence** - for quality discussions
- **Management tool** - helps leads make decisions

---

## üìö Course Concepts Demonstrated

This project demonstrates **6 key concepts** from the Kaggle 5-Day Agents Course (minimum requirement: 3):

### 1. ‚úÖ Multi-Agent System
- **INPUT agents:** Audit Orchestrator, Security Scanner, Complexity Analyzer
- **OUTPUT agents:** Query Agent, Trend Analyzer, Report Generator
- **Coordination:** Sequential and parallel execution patterns

### 2. ‚úÖ Custom Tools Integration
- **GitHub API:** Branch monitoring, webhook handling
- **Bandit:** Security vulnerability detection
- **Radon:** Cyclomatic complexity measurement
- **Git:** Repository cloning and state management

### 3. ‚úÖ Memory System (RAG) - **Core Differentiator**
- **Vertex AI RAG Corpus** stores complete audit history
- **Natural language queries** retrieve relevant audits
- **Temporal indexing** enables trend analysis
- **Persistent memory** across months/years

### 4. ‚úÖ Observability & Monitoring
- Comprehensive logging for each audit
- Query tracing and performance metrics
- Audit success/failure monitoring

### 5. ‚úÖ Agent Evaluation
- LLM-as-judge for audit quality assessment
- Precision/recall metrics for issue detection
- Query response accuracy evaluation

### 6. ‚úÖ Production Deployment
- Deployed on Vertex AI Agent Engine
- GitHub webhook integration for automation
- Production-ready monitoring and error handling

---

## Project Structure

```
capstone/
‚îú‚îÄ‚îÄ src/                  # Core implementation
‚îÇ   ‚îú‚îÄ‚îÄ agents/                 # Agent implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_guardian.py # Main orchestrator (stub)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py             # Agent base classes
‚îÇ   ‚îú‚îÄ‚îÄ connectors/             # External integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github.py           # GitHub API (‚úÖ working)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py             # Base connector
‚îÇ   ‚îú‚îÄ‚îÄ audit/                  # Code analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ engine.py           # AuditEngine (‚úÖ working)
‚îÇ   ‚îú‚îÄ‚îÄ storage/                # Persistence
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_corpus.py       # Vertex AI RAG (stub)
‚îÇ   ‚îú‚îÄ‚îÄ handlers/               # Command handlers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bootstrap.py        # Bootstrap sampling (‚úÖ working)
‚îÇ   ‚îú‚îÄ‚îÄ audit_models.py         # Audit data models (‚úÖ working)
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # Core data models
‚îÇ   ‚îî‚îÄ‚îÄ config.py               # Configuration
‚îÇ
‚îú‚îÄ‚îÄ tests/                # Test suite (188 tests passing)
‚îÇ   ‚îú‚îÄ‚îÄ unit/                   # Unit tests (170 passing)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_changesets.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_memory_bank.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/            # Integration tests (18 passing)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_rag_corpus_integration.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_quality_guardian.py
‚îÇ   ‚îú‚îÄ‚îÄ e2e/                    # End-to-end tests (planned)
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/               # Test data
‚îÇ       ‚îú‚îÄ‚îÄ changesets.py       # Test scenarios
‚îÇ       ‚îú‚îÄ‚îÄ mock_pr.py          # Mock PR data
‚îÇ       ‚îî‚îÄ‚îÄ test-app/           # Flask app with issues
‚îÇ
‚îú‚îÄ‚îÄ demos/                # Interactive demos
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Demo documentation
‚îÇ   ‚îî‚îÄ‚îÄ demo_backend_integration.py  # Backend tools test (‚úÖ working)
‚îÇ
‚îú‚îÄ‚îÄ scripts/              # Dev/deploy utilities
‚îÇ   ‚îú‚îÄ‚îÄ setup_dev.sh
‚îÇ   ‚îú‚îÄ‚îÄ run_tests.sh
‚îÇ   ‚îî‚îÄ‚îÄ lint.sh
‚îÇ
‚îú‚îÄ‚îÄ docs/                 # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ project-plan-v3-quality-guardian.md  # Main plan
‚îÇ   ‚îú‚îÄ‚îÄ architecture-overview.md  # System design
‚îÇ   ‚îú‚îÄ‚îÄ testing-strategy.md       # Testing guide
‚îÇ   ‚îú‚îÄ‚îÄ diagrams/                 # PlantUML diagrams (‚úÖ updated)
‚îÇ   ‚îî‚îÄ‚îÄ archive/                  # Old PR Reviewer docs
‚îÇ
‚îî‚îÄ‚îÄ evalsets/             # Evaluation datasets
    ‚îî‚îÄ‚îÄ test_fixture_prs.evalset.json
```

**Status Legend:**
- ‚úÖ Working (verified with tests/demos)
- üöß In progress
- ‚è≥ Planned

---

## Current Implementation Status (Day 3)

### ‚úÖ Completed Components (~15%)

**Backend Tools (Days 1-3):**
- ‚úÖ **GitHubConnector** - GitHub API integration, fetch commits/repos
- ‚úÖ **AuditEngine** - Security (bandit) + complexity (radon) analysis
- ‚úÖ **FileAudit models** - Per-file quality tracking with Pydantic
- ‚úÖ **Bootstrap Handler** - Sampling strategies (recent/tags/date-range)
- ‚úÖ **Memory Bank** - ADK InMemorySessionService for context
- ‚úÖ **188 tests passing** - Unit (170) + Integration (18)
- ‚úÖ **Backend integration demo** - Verified end-to-end tool chain

**Documentation:**
- ‚úÖ Architecture diagrams updated (Quality Guardian concept)
- ‚úÖ Project plan v3 (10-day timeline)
- ‚úÖ Testing strategy documented

### üöß In Progress (Day 3-4)

**Orchestration Layer:**
- üöß **QualityGuardianAgent** - ADK Agent with command interface
- üöß **RAG Corpus integration** - Vertex AI for persistent storage
- üöß **Command parser** - Parse bootstrap/sync/query intents

### ‚è≥ Planned (Days 4-10)

**Query & Analysis (Days 4-5):**
- ‚è≥ Query Agent - RAG retrieval + Gemini trend analysis
- ‚è≥ Natural language insights generation

**Multi-Agent Coordination (Days 5-7):**
- ‚è≥ Agent-to-agent communication
- ‚è≥ Parallel analysis workflows

**Deployment (Days 8-10):**
- ‚è≥ Vertex AI Agent Engine deployment
- ‚è≥ Production monitoring
- ‚è≥ Evaluation suite

---

## Quick Start

### Run Backend Integration Test

```bash
# Setup
python -m venv .venv
source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows
pip install -r requirements/dev.txt

# Configure
cp .env.example .env.dev
# Edit .env.dev: Add GITHUB_TOKEN, GOOGLE_CLOUD_PROJECT

# Test backend tools
python demos/demo_backend_integration.py
```

**Expected output:** Analysis of 2 commits with quality scores, security issues, file-level breakdown.

### Run Tests

```bash
./scripts/run_tests.sh          # All tests (188 passing)
pytest tests/unit/              # Unit tests only
pytest tests/integration/       # Integration tests only
```

### Prerequisites

- Python 3.11+
- Google Cloud account with required APIs enabled:
  - **Vertex AI API** (for Gemini models and RAG)
  - **Cloud Firestore API** (for audit data storage)
  - **Cloud Logging API** (for production logging)
- GitHub account and personal access token
- ADK CLI installed

**Enable required APIs:**
```bash
gcloud services enable aiplatform.googleapis.com    # Vertex AI
gcloud services enable firestore.googleapis.com     # Firestore
gcloud services enable logging.googleapis.com       # Cloud Logging
```

**Create and configure Service Account:**

The application uses a service account for authentication with GCP services. You need to create one with appropriate permissions:

1. **Create Service Account:**
   - Go to [IAM & Admin > Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts)
   - Click **+ CREATE SERVICE ACCOUNT**
   - Name: `agent-deployment` (or any descriptive name)
   - Description: "Quality Guardian AI agent deployment and runtime"
   - Click **CREATE AND CONTINUE**

2. **Grant Required Roles:**
   
   The service account needs these roles to function properly:
   
   - **Cloud Run Admin** (`roles/run.admin`)
     - Reason: For deploying agents to Cloud Run (if using Cloud Run deployment)
   
   - **Cloud Datastore User** (`roles/datastore.user`)
     - Reason: Read/write access to Firestore for audit data storage
   
   - **Service Account User** (`roles/iam.serviceAccountUser`)
     - Reason: Required to run services as this service account
   
   - **Storage Admin** (`roles/storage.admin`)
     - Reason: Manage Cloud Storage buckets for RAG corpus data
   
   - **Vertex AI User** (`roles/aiplatform.user`)
     - Reason: Access Gemini models and RAG APIs
   
   Add each role by clicking **+ ADD ANOTHER ROLE** and searching for the role name.
   
   Click **CONTINUE** ‚Üí **DONE**

3. **Generate JSON Key:**
   - Click on the created service account
   - Go to **KEYS** tab
   - Click **ADD KEY** ‚Üí **Create new key**
   - Choose **JSON** format
   - Click **CREATE**
   - Save the downloaded file as `service-account-key.json` in project root

4. **Configure Environment:**
   ```bash
   # In your .env file
   GOOGLE_APPLICATION_CREDENTIALS=./service-account-key.json
   GOOGLE_CLOUD_PROJECT=your-project-id
   ```

**Security Note:** Never commit `service-account-key.json` to git. It's already in `.gitignore`.

### First-Time Setup

After enabling APIs, you need to create the required GCP resources:

**1. Create Firestore Database**

Visit: https://console.cloud.google.com/datastore/setup?project=YOUR_PROJECT_ID

- Choose **Firestore Native Mode** (NOT Datastore mode)
- Select region: **us-west1** (or same as your Vertex AI region)
- Database ID: **(default)**

**2. Create RAG Corpus**

The RAG corpus is created automatically on first use, but you can create it manually:

```bash
# Set your project
export GOOGLE_CLOUD_PROJECT=your-project-id

# Run bootstrap to create corpus
python demos/demo_quality_guardian_agent.py
# Then type: "Bootstrap test-org/test-repo with 1 commit"
```

**Verify setup:**
```bash
# Check Firestore
gcloud firestore databases list

# Check RAG corpus (after bootstrap)
python scripts/check_corpus_state.py
```

### Usage: Talk to the Agent

**Deployment:** Agent runs on Vertex AI Agent Engine

**Access Methods:**
- Web interface (deployed endpoint)
- CLI tool (local client talking to deployed agent)
- Kaggle Notebook (for submission demo)

---

### Example Session 1: Bootstrap New Repository

```bash
# Start conversation with deployed agent
$ python -m capstone.cli

üë§ You: Bootstrap microsoft/vscode using tagged releases from last year

ü§ñ Quality Guardian: 
    Connecting to microsoft/vscode...
    ‚úì Found 48 tagged releases (v1.84.0 to v1.95.0)
    ‚úì Analyzing commits... [48/48] (eta: 2m 30s)
    ‚úì Complete!
    
    üìä Summary:
    - Period: Nov 2023 - Nov 2024
    - Commits audited: 48
    - Security issues: 156 total (23 critical, 87 major, 46 minor)
    - Avg complexity: B+ (good)
    - Quality trend: Improving (+8% over year)
    
    ‚úÖ Ready for queries about microsoft/vscode

üë§ You: What are the main security concerns?

ü§ñ Quality Guardian:
    Top security patterns in microsoft/vscode:
    
    üî¥ Recurring Issues:
    1. Path traversal (14 occurrences)
       - Last seen: v1.94.2
       - Files: src/vs/platform/files/*
    
    2. Command injection risk (8 occurrences)
       - Last seen: v1.93.0
       - Files: src/vs/workbench/contrib/terminal/*
    
    üí° Recommendation: Security review of file system and terminal components
```

---

### Example Session 2: Monitor Existing Repository

```bash
üë§ You: Check tensorflow/tensorflow for new commits

ü§ñ Quality Guardian:
    Last audit: Nov 18, 2024 (commit: a1b2c3d)
    Checking for updates...
    
    ‚úì Found 12 new commits (Nov 18-21)
    ‚úì Analyzing... [12/12]
    ‚úì Audit complete
    
    üìâ Quality Delta:
    - Previous: 7.8/10
    - Current: 7.2/10 (-7.7%)
    
    üî¥ New Issues:
    - 3 critical security vulnerabilities
    - Complexity increased in core/ops module
    
    ‚ö†Ô∏è Alert: Quality degradation detected
    
    üí° Review commits: a1b2c3d...f9e8d7c

üë§ You: Show me those critical vulnerabilities

ü§ñ Quality Guardian:
    Critical Security Issues (Nov 18-21):
    
    1. SQL Injection in contrib/data/ops.py
       - Commit: f9e8d7c
       - Line: 342
       - Pattern: Unsanitized user input in query
    
    2. Deserialization vulnerability in core/saved_model
       - Commit: e8d7c6b  
       - Line: 156
       - Pattern: Unsafe pickle.loads()
    
    3. Path traversal in tools/export/exporter.py
       - Commit: d7c6b5a
       - Line: 89
       - Pattern: User-controlled file path
```

### Local Development

```bash
# Run tests
pytest tests/
pip install -r requirements/dev.txt

# Run tests (42 tests passing ‚úÖ)
pytest tests/unit/ -v

# Try interactive demo
python demos/demo_analyzer.py

# Evaluation (TODO: Day 9)
adk eval evalsets/test_fixture_prs.evalset.json
```

### Quick Demo

```bash
# See Analyzer Agent in action
python demos/demo_analyzer.py

# Output shows:
# - Merged state creation (base + PR)
# - Security issues detection (bandit)
# - Complexity analysis (radon)
# - AI recommendations (Gemini 2.0)
```

### Production Deployment (TODO: Day 11)

See [Deployment Guide](docs/deployment.md) when available.

---

## Evaluation & Results

[To be populated after testing]

- **Review Speed:** < 15 seconds per PR
- **Detection Accuracy:** > 80% vs manual review
- **Memory Recall:** > 90% for known patterns
- **False Positive Rate:** < 20%

---

## üîß Technology Stack

- **Framework:** Google Agent Development Kit (ADK)
- **LLM:** Gemini 2.5 Flash & Pro
- **Memory:** ADK Memory Bank
- **Tools:** PyGithub, GitPython, Radon, Bandit
- **Deployment:** Vertex AI Agent Engine
- **Observability:** Cloud Logging

---

## üìù Project Status

**Timeline:** Nov 18 - Dec 1, 2025 (13 days)

**Current Phase:** Day 1 - Design & Setup

See [Project Plan](docs/project-plan.md) for detailed timeline.

---

## Competition Details

- **Competition:** Kaggle 5-Day Agents Intensive Capstone Project
- **Track:** Enterprise Agents
- **Target:** Top-3 placement
- **Submission Deadline:** December 1, 2025 at 11:59 AM PT

---

## üìö Documentation

- [Project Plan](docs/project-plan.md) - Complete implementation timeline
- [Competition Requirements](docs/capstone-requirements.md) - Rubric and rules
- [Market Trends Analysis](docs/market-trends-2025.md) - Industry context
- [Architecture Design](docs/architecture.md) - Technical details (coming soon)
- [Deployment Guide](docs/deployment.md) - Production setup (coming soon)

---

## ü§ù Contributing

This is a competition entry project. Development is currently closed.

---

## üìÑ License

This project is developed for the Kaggle 5-Day Agents Intensive Capstone Project.

---

## üôè Acknowledgments

- Google ADK Team for the framework
- Kaggle for organizing the competition
- GitHub for Agent HQ inspiration

---

**Built with ‚ù§Ô∏è using Google ADK**

Last Updated: November 18, 2025
